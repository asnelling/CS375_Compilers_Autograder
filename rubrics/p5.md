# Grading Guideline for Project 5 --- parsing pasrec.pas and graph1i.pas

**Your code will be checked for plagiarism against each other as well as some online github code using moss. If you get caught, you will get a 0 for this project.**

## Rubrics

The grading of this project is divided into the following two parts:

1. `pasrec.pas` ==> 90 points.
    There are 16 unit tests in the `test_p5` directory. 
    Each test is extracted from `pasrec.pas` (or something similar) and focuses on 
    one part of it. 
    The first 4 unit tests are testing symbol tables only.
    The points of each unit test is detailed in the below table.
    You can get partial points if only part of the result is correct. 
    The samples are in the `sample_p5` directory. 
    
| Test No. | Points | Content                                |
| -------- | ------ | -------------------------------------- |
| 00       | 4      | instenum                               |
| 01       | 5      | instpoint                              |
| 02       | 8      | instrec                                |
| 03       | 8      | instarray                              |
| 04       | 4      | while loop                             |
| 05       | 4      | label/goto                             |
| 06       | 5      | write and writeln in makefuncall       |
| 07       | 5      | new() in makefuncall+size of record    |
| 08       | 8      | simple reducedot                       |
| 09       | 6      | dopoint->reducedot                     |
| 10       | 4      | dopoint->reducedot->reducedot          |
| 11       | 4      | dopoint->reducedot->dopoint->reducedot |
| 12       | 5      | arrayref-1D-constantIdx->reducedot     |
| 13       | 6      | arrayref-1D-varIdx->reducedot          |
| 14       | 6      | arrayref-2D-constantIdx-constantIdx    |
| 15       | 8      | arrayref-2D-varIdx-constantIdx         |
| Total    | 90     | | 
2. `graph1i.pas` ==> 10 points. Please make sure your new parser can still handle it.
    The [rubrics of project 4](https://github.com/zhanglx13/CS375_Compilers_Autograder/blob/master/rubrics/p3.md#Rubrics) will be used except the total points are scaled to 10.

## Submissions

- parse.y (for Yacc) or parsc.c (for C)
- lexan.l (If not found, the one from project 2 will be used)
- Any other files that you have modified.

## Autograding

Same as [project 3](https://github.com/zhanglx13/CS375_Compilers_Autograder/blob/master/rubrics/p3.md#Autograding)
except that the command for running the autograder should be 
```
./grade.sh -p 5 -d workingDir
```
You should make sure that `graph1i.pas` is in your workingDir.

**Remember to copy `printtoken.c`, `pprint.c`, and `print.h` from `cs375_minimal`
directory into your workingdir before running the autograder.**

**The autograder uses clang to compile your parser and runs on the cs machine,
which uses bison 3.0.4.**
To use `clang` to compile your parser, make sure you copied `makefile` in `/cs375_minimal/`
into your working dir. 
This `makefile` is a compact version of the original `makefile` provided in the `cs375`
directory.

Another note is that I rewrote the symbol table checker, which is integrated into
the grading scripts. 
Therefore, you will no longer need the `symTable` dir.

### How to read autograder's output

You will get 100 points if you see the following output 
(unless you are caught for plagiarism)
```
|
|  graph1i.pas  
|
> Check symbol table:  All Good!!
> Check parsing tree:  All Good!!
|
|  pasrec.pas  
|
> TEST 00 (4):  All Good!!
> TEST 01 (5):  All Good!!
> TEST 02 (8):  All Good!!
> TEST 03 (8):  All Good!!
> TEST 04 (4):  All Good!!
> TEST 05 (4):  All Good!!
> TEST 06 (5):  All Good!!
> TEST 07 (5):  All Good!!
> TEST 08 (8):  All Good!!
> TEST 09 (6):  All Good!!
> TEST 10 (4):  All Good!!
> TEST 11 (4):  All Good!!
> TEST 12 (5):  All Good!!
> TEST 13 (6):  All Good!!
> TEST 14 (6):  All Good!!
> TEST 15 (8):  All Good!!
```
For `graph1i.pas`, the autograder first checks the symbol table and then the parse tree.
If something is wrong, the diff message will be printed in the corresponding section.

For `pasrec.pas`, the autograder checks your parser with each unit test.
The number wrapped in parenthesis after `TEST NN` is the total points for this unit test.
If something is wrong, the diff message will be printed after each unit test's section,
which is explained below

#### Symbol Table Checker

The error message of the first 4 unit tests should be intuitive. 
Possible messages are

1. `Incorrect CONST`: one or more of the CONST entries are not correct. 
   A diff result will be printed out. Contents after `<` belongs to the sample and 
   contents after the `>` belongs to your output.
2. `Incorrect TYPE tname`: fields of TYPE `tname` in your symbol table are not correct.
   It can be the size of the type or the underlying type.
   A diff result will be printed out.
3. `Incorrect TYPE tname (should not be here)`: TYPE `tname` is found in your 
   symbol table but not in the sample.
4. `Incorrect TYPE tname (missing)`: TYPE `tname` is not found in your symbol table.
5. `Incorrect VAR vname (should not be here)`: VAR `vname` is found in your symbol table
   but not in the sample.
6. `Incorrect VAR vname (missing)`: VAR `vname` is not found in your symbol table
7. `Incorrect VAR vname (basicdt < sample | > yours)`: the basicdt of VAR `vname` is
   not correct. The correct basicdt and yours are printed in the parenthesis.
8. `Incorrect VAR vname (size < sample | > yours)`: The VAR `vname`'s size is 
   not correct. The correct size and yours are printed in the parenthesis.
9. `Incorrect VAR vname (typ, which should match typ of tname)`: the `typ` field of
   VAR `vname` is not the same as `typ` of TYPE `tname`. 
   **Attention**: When a VAR has a type which is defined in the type block, its `typ`
   should be the same as the type's `typ`, not the type's address.
10. `Incorrect VAR vname (typ)`: the `typ` of VAR `vname` is not correct. 
    This is for VAR's with basic data type (real or integer).
11. `Incorrect VAR vname (type full)`: The full underlying type of VAR `vname` is
    not correct. This is usually caused by an incorrect TYPE entry (probably the 
    size field).
    A diff result will be printed out.
12. `Incorrect VAR vname (offset < sample | > yours)`: the offset of VAR `vname` is
   not correct. The correct offset and yours are printed in the parenthesis. 
   This is usually caused by incorrect alignment of the VAR.
   **Attention**: alignment of a VAR is computed in `instvars()` by calling `alignsize()`,
   which returns the alignment requirement according to the kind of the VAR's symtype.
   One of the mistakes is setting VAR's symtype to a TYPESYM. If this is the case,
   check `findtype()`.
   The alignment requirement for different types are summarized in the following table 
   for reference.
   
| type     | alignment |
| -------- | --------- |
| integer  | 4         |
| real     | 8         |
| pointer  | 8         |
| subrange | 4         |
| record   | 16        |
| array    | 16        |
  
#### Outputs of other unit tests

If something wrong with unit test 04 to 15, a diff result will be printed out.
Below is an example output
```
> TEST 09 (6):  6 / 8
3c3
< (progn (:= (aref (^ john) 32) 2)
---
> (progn (:= (aref (^ john) 28) 2)
5,8c5,8
< (:= (aref (^ john) 8) mary)
< (:= (aref (^ john) 40) 4.000000e+04)
< (:= (aref (^ fred) 8) 0)
< (:= (aref (^ mary) 16) c)
---
> (:= (aref (^ john) 4) mary)
> (:= (aref (^ john) 32) 4.000000e+04)
> (:= (aref (^ fred) 4) 0)
> (:= (aref (^ mary) 12) c)
10c10
< (:= ptr (aref (^ ptr) 8))))
---
> (:= ptr (aref (^ ptr) 4))))
```
`6/8` means there are 6 out of 8 lines in your output do not match that in the sample.
Note that mismatch does not necessarily mean your output is incorrect. 
Each section of the diff result shows the detail of the difference. 
Contents after `<` belong to the sample and contents after `>` belong to your output.
Sample and your output are separated by `---`.
`x,ycm,n` means line `x` to `y` in the sample is changed to line `m` to `n` in your output.
You may also see `x,ydm`, which means line `x` to `y` in the sample are not found 
in your output,
and `xam,n`, which means line `m` to `n` in your output are not found in the sample.



## Notes

Make sure you read the [notes of project 3](https://github.com/zhanglx13/CS375_Compilers_Autograder/blob/master/rubrics/p3.md#Notes)
and the [notes of project 4](https://github.com/zhanglx13/CS375_Compilers_Autograder/blob/master/rubrics/p4.md#Notes)

Here are some more notes for this project

### `res 15`?

If you see `res 15` somewhere in your parse tree, it means that your parser considers
`nil` as a reserved word, which further means `nil` is not included in your grammar.

Similarly, if you see `res xx` in your parse tree, you can look it up in token.h to see
which reserved word it refers to. 

### Make sure you initialize everything before using it

Let's say you are trying to reduce `ac[7].re`. 
After you figure out that `ac[7]` is a complex, you probably need to go through 
its field list to locate `re` using an index `i`. 
If you messed up with `ac[7]`, which means the pointers of the `recordsym` is 
not properly set, you will not find `re` in the field list. 
However, if you do not initialize `i`, its value could be set to 0 by some compiler. 
In this case, it seems to you that the 0th field matches `re` and you happen 
to get the correct result.

### Make sure you set the type of `aref` properly

When you do type coercion for 
```
john^.location.re := 3;
```
The lhs will be converted to 
```
(aref (^ john) 16)
```
Then the correctness of type coercion will depend on the type of aref.
In general, if `aref` refers to a complex type, such as RECORD, POINTER, the 
**symtype** field of `aref` should be properly set. If `aref` refers to a basic 
type, such as real and integer, the **basicdt** field of `aref` should also be 
properly set. 

For the next project --- codegen, if the type of `aref` is not properly set, 
the wrong register might be chosen for the `aref` structure. So make sure 
you get this right.
